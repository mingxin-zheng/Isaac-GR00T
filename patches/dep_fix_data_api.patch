diff --git a/gr00t/configs/finetune_config.py b/gr00t/configs/finetune_config.py
index 61a650f..08b4eb0 100644
--- a/gr00t/configs/finetune_config.py
+++ b/gr00t/configs/finetune_config.py
@@ -116,3 +116,15 @@ class FinetuneConfig:
 
     num_shards_per_epoch: int = int(1e5)
     """Number of shards to use for the dataset. reduce this number if vram is limited."""
+
+    video_backend: str = "torchcodec"
+    """
+    Video decoding backend to use for loading video frames.
+    Options: "torchcodec", "decord", "ffmpeg", "opencv".
+    """
+
+    override_pretraining_statistics: bool = False
+    """
+    If True, override the action/state statistics from the pretrained checkpoint
+    with statistics computed from the fine-tuning dataset.
+    """
diff --git a/gr00t/experiment/launch_finetune.py b/gr00t/experiment/launch_finetune.py
index f5deb7e..45e8fc0 100644
--- a/gr00t/experiment/launch_finetune.py
+++ b/gr00t/experiment/launch_finetune.py
@@ -88,5 +88,7 @@ if __name__ == "__main__":
     config.data.shard_size = ft_config.shard_size
     config.data.episode_sampling_rate = ft_config.episode_sampling_rate
     config.data.num_shards_per_epoch = ft_config.num_shards_per_epoch
+    config.data.video_backend = ft_config.video_backend
+    config.data.override_pretraining_statistics = ft_config.override_pretraining_statistics
 
     run(config)
diff --git a/pyproject.toml b/pyproject.toml
index f71ae4a..0f2c5b5 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -22,7 +22,7 @@ dependencies = [
     "termcolor==3.2.0",
     "torch==2.7.0",
     "torchvision==0.22.0",
-    "transformers==4.53.0",
+    "transformers==4.51.3",
     "tyro==0.9.17",
     "flash-attn==2.7.4.post1",
     "click==8.1.8",
